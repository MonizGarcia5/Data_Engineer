{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e485ae94-d52c-455f-acdb-7f6abfcab7b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Carga dados Yellow Taxi Trip - Camada Prata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ab832a-f7b0-4d25-9d46-9f6a4233338e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType, IntegerType, LongType\n",
    "\n",
    "# \uD83D\uDD39 Cria a sessão Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# \uD83D\uDD39 Criar schema se não existirem na camada prata\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS tlc_trip\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS tlc_trip.prata\")\n",
    "\n",
    "# Ler dados da bronze (todos como string)\n",
    "df_bronze = spark.read.format(\"delta\").load(\"tlc_trip.bronze.yellow_taxi_trip\")\n",
    "\n",
    "# Definição do schema com tipos corretos\n",
    "schema = StructType([\n",
    "    StructField(\"VendorID\", LongType(), True),\n",
    "    StructField(\"tpep_pickup_datetime\", TimestampType(), True),\n",
    "    StructField(\"tpep_dropoff_datetime\", TimestampType(), True),\n",
    "    StructField(\"passenger_count\", DoubleType(), True),\n",
    "    StructField(\"trip_distance\", DoubleType(), True),\n",
    "    StructField(\"RatecodeID\", DoubleType(), True),\n",
    "    StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "    StructField(\"PULocationID\", LongType(), True),\n",
    "    StructField(\"DOLocationID\", LongType(), True),\n",
    "    StructField(\"payment_type\", LongType(), True),\n",
    "    StructField(\"fare_amount\", DoubleType(), True),\n",
    "    StructField(\"extra\", DoubleType(), True),\n",
    "    StructField(\"mta_tax\", DoubleType(), True),\n",
    "    StructField(\"tip_amount\", DoubleType(), True),\n",
    "    StructField(\"tolls_amount\", DoubleType(), True),\n",
    "    StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "    StructField(\"total_amount\", DoubleType(), True),\n",
    "    StructField(\"congestion_surcharge\", DoubleType(), True),\n",
    "    StructField(\"airport_fee\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "# Lê os dados da camada bronze (presumindo que são todos strings)\n",
    "df_bronze = spark.read.format(\"delta\").table(\"tlc_trip.bronze.yellow_taxi_trip\")\n",
    "\n",
    "# Aplica as conversões usando cast em cada coluna\n",
    "df_silver = df_bronze.select(\n",
    "    col(\"VendorID\").cast(LongType()).alias(\"VendorID\"),\n",
    "    col(\"tpep_pickup_datetime\").cast(TimestampType()).alias(\"tpep_pickup_datetime\"),\n",
    "    col(\"tpep_dropoff_datetime\").cast(TimestampType()).alias(\"tpep_dropoff_datetime\"),\n",
    "    col(\"passenger_count\").cast(DoubleType()).alias(\"passenger_count\"),\n",
    "    col(\"trip_distance\").cast(DoubleType()).alias(\"trip_distance\"),\n",
    "    col(\"RatecodeID\").cast(DoubleType()).alias(\"RatecodeID\"),\n",
    "    col(\"store_and_fwd_flag\").alias(\"store_and_fwd_flag\"),  # já string\n",
    "    col(\"PULocationID\").cast(LongType()).alias(\"PULocationID\"),\n",
    "    col(\"DOLocationID\").cast(LongType()).alias(\"DOLocationID\"),\n",
    "    col(\"payment_type\").cast(LongType()).alias(\"payment_type\"),\n",
    "    col(\"fare_amount\").cast(DoubleType()).alias(\"fare_amount\"),\n",
    "    col(\"extra\").cast(DoubleType()).alias(\"extra\"),\n",
    "    col(\"mta_tax\").cast(DoubleType()).alias(\"mta_tax\"),\n",
    "    col(\"tip_amount\").cast(DoubleType()).alias(\"tip_amount\"),\n",
    "    col(\"tolls_amount\").cast(DoubleType()).alias(\"tolls_amount\"),\n",
    "    col(\"improvement_surcharge\").cast(DoubleType()).alias(\"improvement_surcharge\"),\n",
    "    col(\"total_amount\").cast(DoubleType()).alias(\"total_amount\"),\n",
    "    col(\"congestion_surcharge\").cast(DoubleType()).alias(\"congestion_surcharge\"),\n",
    "    col(\"airport_fee\").cast(DoubleType()).alias(\"airport_fee\"),\n",
    ")\n",
    "\n",
    "# Gravar o dataframe silver no Delta novamente\n",
    "df_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"tlc_trip.prata.yellow_taxi_trip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e60cc2f9-8612-4264-af9d-5853703e7584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Tratamento dos dados \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8097dcc9-4b60-4a31-86fc-0fbbb2be1b07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total original: 1440391\nRegistros válidos: 1354309\nRegistros inválidos: 54\nRegistros removidos: 86028\nSoma válidos + inválidos + removidos = 1440391\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, upper, when, year, month, dayofmonth\n",
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# \uD83D\uDD39 Cria a sessão Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Carregar dados da camada prata já tipados\n",
    "df = spark.table(\"tlc_trip.prata.yellow_taxi_trip\")\n",
    "\n",
    "#  Remover registros inconsistentes\n",
    "df_clean = df.filter(\n",
    "    (col(\"tpep_pickup_datetime\").isNotNull()) &\n",
    "    (col(\"VendorID\").isNotNull()) &\n",
    "    (col(\"trip_distance\") > 0) &\n",
    "    (col(\"passenger_count\") > 0) &\n",
    "    (col(\"fare_amount\") >= 0)\n",
    ")\n",
    "\n",
    "# Gerar DataFrame somente com os registros removidos\n",
    "df_removed = df.subtract(df_clean)\n",
    "\n",
    "# Normalizar colunas\n",
    "df_clean = df_clean.withColumn(\n",
    "    \"store_and_fwd_flag\", upper(col(\"store_and_fwd_flag\"))\n",
    ")\n",
    "\n",
    "# Colunas derivadas para facilitar análises temporais\n",
    "df_clean = df_clean.withColumn(\"pickup_year\", year(col(\"tpep_pickup_datetime\")))\n",
    "df_clean = df_clean.withColumn(\"pickup_month\", month(col(\"tpep_pickup_datetime\")))\n",
    "df_clean = df_clean.withColumn(\"pickup_day\", dayofmonth(col(\"tpep_pickup_datetime\")))\n",
    "\n",
    "# Validar regra simples de negócio\n",
    "df_clean = df_clean.withColumn(\n",
    "    \"total_amount_check\",\n",
    "    (col(\"total_amount\") >= (col(\"fare_amount\") + col(\"tip_amount\") + col(\"tolls_amount\") + col(\"extra\")))\n",
    ")\n",
    "\n",
    "# Filtrar inválidos\n",
    "df_invalid = df_clean.filter(col(\"total_amount_check\") == False)\n",
    "\n",
    "# Filtrar válidos excluindo os inválidos\n",
    "df_valid = df_clean.filter(col(\"total_amount_check\") == True)\n",
    "\n",
    "print(f\"Total original: {df.count()}\")\n",
    "print(f\"Registros válidos: {df_valid.count()}\")\n",
    "print(f\"Registros inválidos: {df_invalid.count()}\")\n",
    "print(f\"Registros removidos: {df_removed.count()}\")\n",
    "\n",
    "print(f\"Soma válidos + inválidos + removidos = {df_valid.count() + df_invalid.count() + df_removed.count()}\")\n",
    "\n",
    "# Gravar os dados tratados e válidos na camada prata\n",
    "df_valid.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"tlc_trip.prata.yellow_taxi_trip_tratada\")\n",
    "\n",
    "# Gravar os dados inválidos na camada prata\n",
    "df_invalid.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"tlc_trip.prata.yellow_taxi_trip_invalida\")\n",
    "\n",
    "# Gravar os dados removidos na camada prata\n",
    "df_removed.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"tlc_trip.prata.yellow_taxi_trip_removido\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pra_yellow_taxi_trip",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}