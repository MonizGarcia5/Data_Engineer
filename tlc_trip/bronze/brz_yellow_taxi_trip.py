# Databricks notebook source
# MAGIC %md ##Carga dados Yellow Taxi Trip - Camada Bronze

# COMMAND ----------

import requests
from pyspark.sql import SparkSession

# ğŸ”¹ Cria a sessÃ£o Spark
spark = SparkSession.builder.getOrCreate()

# ğŸ”¹ Criar catÃ¡logo e schema se nÃ£o existirem na camada bronze
spark.sql("CREATE CATALOG IF NOT EXISTS tlc_trip")
spark.sql("CREATE SCHEMA IF NOT EXISTS tlc_trip.bronze")

# ğŸ”¹ ID do dataset "Yellow Taxi Trip Data" (2023) no NYC Open Data
dataset_id = "4b4i-vvec"

# ğŸ”¹ URL base da API SODA do Socrata
base_url = f"https://data.cityofnewyork.us/resource/{dataset_id}.json"

# ğŸ”¹ Filtro de data (apenas viagens de marÃ§o/2023)
# Usando a sintaxe SoQL no parÃ¢metro "$where"
where_clause = "tpep_pickup_datetime between '2023-01-01T00:00:00' and '2023-04-30T23:59:59'"

# ğŸ”¹ ConfiguraÃ§Ã£o de paginaÃ§Ã£o
limit = 50000   # mÃ¡ximo de registros por requisiÃ§Ã£o (Socrata aceita atÃ© 50k)
offset = 0      # posiÃ§Ã£o inicial para buscar os dados

# Lista para acumular DataFrames parciais
all_dfs = []

# ğŸ”„ Loop de paginaÃ§Ã£o atÃ© trazer todos os registros
while True:
    # ParÃ¢metros da requisiÃ§Ã£o para a API
    params = {
        "$where": where_clause,  # filtro de data
        "$limit": limit,         # quantidade de registros por requisiÃ§Ã£o
        "$offset": offset        # deslocamento para prÃ³xima pÃ¡gina
    }
    
    print(f"ğŸ”„ Baixando registros {offset} atÃ© {offset + limit} ...")
    
    # Faz a requisiÃ§Ã£o HTTP GET
    response = requests.get(base_url, params=params)
    
    # Converte o retorno JSON para objeto Python
    data = response.json()
    
    # Se nÃ£o houver mais dados, encerra o loop
    if not data:
        break
    
    # Converte lista de dicionÃ¡rios para DataFrame Spark
    df_temp = spark.createDataFrame(data)
    
    # Adiciona o DataFrame parcial Ã  lista
    all_dfs.append(df_temp)
    
    # AvanÃ§a para prÃ³xima "pÃ¡gina" de registros
    offset += limit

# ğŸ”¹ Une todos os DataFrames em um Ãºnico
if all_dfs:
    # ComeÃ§a com o primeiro DataFrame
    df_final = all_dfs[0]
    
    # Faz uniÃ£o com os demais DataFrames (por nome de coluna)
    for df in all_dfs[1:]:
        df_final = df_final.unionByName(df)
    
    # Mostra o total de registros carregados
    print(f"âœ… Total de registros carregados: {df_final.count()}")

# Salvar a camada Bronze unificada
df_final.write.format("delta") \
    .mode("overwrite") \
    .saveAsTable("tlc_trip.bronze.yellow_taxi_trip")
