from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Spark and Hive")\
                                .config("spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version", "2")\
                                .config("spark.speculation", "false").config("hive.exec.dynamic.partition", "true")\
                                .config("hive.exec.dynamic.partition.mode", "nonstrict")\
                                .enableHiveSupport()\
                                .getOrCreate()

def create_db(db_name):
    query_db="CREATE DATABASE  IF NOT EXISTS {}".format(db_name)
    spark.sql(query_db)

def create_table(db_name,tb_name,fl_name):
    query_tb="CREATE TABLE  IF NOT EXISTS {}.{}  USING csv OPTIONS (path {}".format(db_name,tb_name,fl_name)
    spark.sql(query_tb)

data_base="db_goldr" 
create_db(data_base)
   
data_base="db_silver" 
create_db(data_base)

data_base="db_bronze" 
create_db(data_base)

table="di_produto"
file= """"/FileStore/tables/bronze/PRODUTO.csv",header="true",delimiter=";")"""
create_table(data_base,table,file)

table="di_regiao"
file= """"/FileStore/tables/bronze/REGIAO.csv",header="true",delimiter=";")"""
create_table(data_base,table,file)

table="fa_venda"
file= """"/FileStore/tables/bronze/VENDA_REGIAO.csv",header="true",delimiter=";")"""
create_table(data_base,table,file)